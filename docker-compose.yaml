version: "3.8"

x-opensearch-common: &opensearch-common
  image: opensearchproject/opensearch:${OPENSEARCH_VERSION}
  environment:
    - cluster.name=os-cluster
    - discovery.seed_hosts=os01,os02,os03
    - cluster.initial_cluster_manager_nodes=os01,os02,os03
    - bootstrap.memory_lock=true # along with the memlock settings below, disables swapping
    - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # minimum and maximum Java heap size, recommend setting both to 50% of system RAM
    # - discovery.seed_hosts=os01,os02,os03
    # - cluster.initial_master_nodes=os01,os02,os03
    # - network.host="0.0.0.0"
  ulimits:
    memlock:
      soft: -1
      hard: -1
    nofile:
      soft: 65536 # maximum number of open files for the OpenSearch user, set to at least 65536 on modern systems
      hard: 65536
  logging:
    driver: "json-file"
    options:
      max-size: "100m"
      max-file: "1"
  networks:
    - api-harbor-network

services:
  server:
    container_name: server
    build:
      context: ./server
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    networks:
      - api-harbor-network
    depends_on:
      - os01
      - os02
      - os03
      - mongodb
      - kibana
      # - filebeat
      - temporal

  worker:
    container_name: worker
    build:
      context: ./worker
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    networks:
      - api-harbor-network
    depends_on:
      - os01
      - os02
      - os03
      - mongodb
      - kibana
      # - filebeat
      - temporal

  elasticsearch:
    container_name: elasticsearch
    environment:
      - cluster.routing.allocation.disk.threshold_enabled=true
      - cluster.routing.allocation.disk.watermark.low=512mb
      - cluster.routing.allocation.disk.watermark.high=256mb
      - cluster.routing.allocation.disk.watermark.flood_stage=128mb
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms256m -Xmx256m
      - xpack.security.enabled=false
    image: elasticsearch:${ELASTICSEARCH_VERSION}
    networks:
      - api-harbor-network
    expose:
      - 9200
    volumes:
      - /var/lib/elasticsearch/data

  postgresql:
    container_name: postgresql
    environment:
      POSTGRES_PASSWORD: temporal
      POSTGRES_USER: temporal
    image: postgres:${POSTGRESQL_VERSION}
    networks:
      - api-harbor-network
    expose:
      - 5432:5432
    volumes:
      - /var/lib/postgresql/data

  temporal:
    container_name: temporal
    depends_on:
      depends_on:
        - postgresql
        - elasticsearch
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=postgresql
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
      - ENABLE_ES=true
      - ES_SEEDS=opensearch
      - ES_VERSION=v7
    image: temporalio/auto-setup:${TEMPORAL_VERSION}
    networks:
      - api-harbor-network
    ports:
      - 7233:7233
    labels:
      kompose.volume.type: configMap
    volumes:
      - ./dynamicconfig:/etc/temporal/config/dynamicconfig

  temporal-admin-tools:
    container_name: temporal-admin-tools
    depends_on:
      - temporal
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CLI_ADDRESS=temporal:7233
    image: temporalio/admin-tools:${TEMPORAL_VERSION}
    networks:
      - api-harbor-network
    stdin_open: true
    tty: true

  temporal-ui:
    container_name: temporal-ui
    depends_on:
      - temporal
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    image: temporalio/ui:${TEMPORAL_UI_VERSION}
    networks:
      - api-harbor-network
    ports:
      - 8080:8080

  # filebeat:
  #   image: docker.elastic.co/beats/filebeat:${STACK_VERSION}
  #   volumes:
  #     - ./filebeat:/usr/share/filebeat/
  #     - /var/lib/docker/containers:/var/lib/docker/containers:ro
  #   depends_on:
  #     - opensearch
  #     - kibana

  mongodb:
    container_name: mongodb
    image: mongo:latest
    ports:
      - "${MONGO_PORT}:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password

  mongo-express:
    container_name: mongo-express
    image: mongo-express
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_SERVER: mongodb
      ME_CONFIG_MONGODB_PORT: ${MONGO_PORT}
      ME_CONFIG_MONGODB_ADMINUSERNAME: admin
      ME_CONFIG_MONGODB_ADMINPASSWORD: password

  prometheus:
    container_name: prometheus
    image: prom/prometheus:v2.30.3
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus:/etc/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"

  grafana:
    container_name: grafana
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SECURITY_ADMIN_USER=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./grafana:/var/lib/grafana

  dragonfly:
    image: "docker.dragonflydb.io/dragonflydb/dragonfly"
    ulimits:
      memlock: -1
    ports:
      - "6379:6379"
    # For better performance, consider `host` mode instead `port` to avoid docker NAT.
    # `host` mode is NOT currently supported in Swarm Mode.
    # https://docs.docker.com/compose/compose-file/compose-file-v3/#network_mode
    # network_mode: "host"
    volumes:
      - dragonfly_data:/data

volumes:
  elasticsearch-data:
    driver: local

  kibana-data:
    driver: local

  prometheus_data:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: ./prometheus_data
  grafana_data:
    driver: local
    driver_opts:
      o: bind
      type: none
      device: ./grafana_data
  filebeat_data:
  mongo_data:
  temporal_data:
  opensearch_data1:
  opensearch_data2:
  opensearch_data3:
  dragonfly_data:

networks:
  api-harbor-network:
    driver: bridge
    name: api-harbor-network
